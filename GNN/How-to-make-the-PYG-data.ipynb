{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset from parse trees for input to PYG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph is used to model pairwise relations (edges) between objects (nodes). A single graph in PyG is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "* __data.x__: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "\n",
    "* __data.edge_index__: Graph connectivity in `COO` format with shape `[2, num_edges]` and type `torch.long`\n",
    "\n",
    "* __data.edge_attr__: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "\n",
    "* __data.y__: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "\n",
    "* __data.pos__: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /Users/kylehamilton/opt/anaconda3\n",
      "torch                 *  /Users/kylehamilton/opt/anaconda3/envs/torch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x7ffd69a05ac0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "from benepar import BeneparComponent, NonConstituentException\n",
    "# nlp.add_pipe(BeneparComponent(\"benepar_en3\"))\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TypeError: Descriptors cannot not be created directly.\n",
    "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
    "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
    " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
    " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
    "\n",
    "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tedboy.github.io/nlps/generated/generated/nltk.ParentedTree.html\n",
    "import nltk\n",
    "from nltk import Tree, ParentedTree, CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"If he crosses, he joins Bush II in the history books.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(text):\n",
    "    doc = nlp(text)\n",
    "    sent = list(doc.sents)[0]\n",
    "    parse_tree = Tree.fromstring('(' + sent._.parse_string + ')')\n",
    "    parse_string = sent._.parse_string\n",
    "    return (parse_tree, parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = d(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ -> S,\n",
       " S -> SBAR , NP VP .,\n",
       " SBAR -> IN S,\n",
       " IN -> 'If',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'he',\n",
       " VP -> VBZ,\n",
       " VBZ -> 'crosses',\n",
       " , -> ',',\n",
       " NP -> PRP,\n",
       " PRP -> 'he',\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'joins',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Bush',\n",
       " NNP -> 'II',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> DT NN NNS,\n",
       " DT -> 'the',\n",
       " NN -> 'history',\n",
       " NNS -> 'books',\n",
       " . -> '.']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"296px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,576.0,296.0\" width=\"576px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /></svg><svg width=\"100%\" x=\"0%\" y=\"2em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"25%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">SBAR</text></svg><svg width=\"22.2222%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">If</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.1111%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.7778%\" x=\"22.2222%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"35.7143%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">he</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.8571%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"64.2857%\" x=\"35.7143%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">crosses</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.8571%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.1111%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.5%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.16667%\" x=\"25%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.0833%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.94444%\" x=\"29.1667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">he</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.6389%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"59.7222%\" x=\"36.1111%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"16.2791%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">joins</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.13953%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"25.5814%\" x=\"16.2791%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"54.5455%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Bush</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.2727%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"45.4545%\" x=\"54.5455%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">II</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.2727%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.0698%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.1395%\" x=\"41.8605%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"16%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84%\" x=\"16%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"23.8095%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.9048%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.8571%\" x=\"23.8095%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">history</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.2381%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">books</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.9302%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.9722%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.16667%\" x=\"95.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.9167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"0em\" y2=\"2em\" /></svg>"
      ],
      "text/plain": [
       "Tree('', [Tree('S', [Tree('SBAR', [Tree('IN', ['If']), Tree('S', [Tree('NP', [Tree('PRP', ['he'])]), Tree('VP', [Tree('VBZ', ['crosses'])])])]), Tree(',', [',']), Tree('NP', [Tree('PRP', ['he'])]), Tree('VP', [Tree('VBZ', ['joins']), Tree('NP', [Tree('NNP', ['Bush']), Tree('NNP', ['II'])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('DT', ['the']), Tree('NN', ['history']), Tree('NNS', ['books'])])])]), Tree('.', ['.'])])])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert Tags to node indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(0 (1 (2 If) (3 (4 (5 he)) (6 (7 crosses)))) (8 ,) (9 (10 he)) (11 (12 joins) (13 (14 Bush) (15 II)) (16 (17 in) (18 (19 the) (20 history) (21 books)))) (22 .))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_dict = defaultdict(int)\n",
    "\n",
    "sent_parse = d(text)[1]\n",
    "new_string = \"\"\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for item in sent_parse.split(\" \"):\n",
    "    if item.startswith('('):\n",
    "        nodes_dict[idx]=item[1:]\n",
    "        new_string+='('+str(idx)+\" \"\n",
    "        idx += 1\n",
    "    else:\n",
    "        new_string+=item+\" \"\n",
    "\n",
    "new_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {0: 'S',\n",
       "             1: 'SBAR',\n",
       "             2: 'IN',\n",
       "             3: 'S',\n",
       "             4: 'NP',\n",
       "             5: 'PRP',\n",
       "             6: 'VP',\n",
       "             7: 'VBZ',\n",
       "             8: ',',\n",
       "             9: 'NP',\n",
       "             10: 'PRP',\n",
       "             11: 'VP',\n",
       "             12: 'VBZ',\n",
       "             13: 'NP',\n",
       "             14: 'NNP',\n",
       "             15: 'NNP',\n",
       "             16: 'PP',\n",
       "             17: 'IN',\n",
       "             18: 'NP',\n",
       "             19: 'DT',\n",
       "             20: 'NN',\n",
       "             21: 'NNS',\n",
       "             22: '.'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a parse tree given the new string where tags have been replaced with node ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tree.fromstring(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert the tree to a list of edges of the form (source_node, destination_node)\n",
    "* First, get the productions\n",
    "* Next, convert productions to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 -> 1 8 9 11 22, 1 -> 2 3, 2 -> 'If', 3 -> 4 6, 4 -> 5, 5 -> 'he', 6 -> 7, 7 -> 'crosses', 8 -> ',', 9 -> 10, 10 -> 'he', 11 -> 12 13 16, 12 -> 'joins', 13 -> 14 15, 14 -> 'Bush', 15 -> 'II', 16 -> 17 18, 17 -> 'in', 18 -> 19 20 21, 19 -> 'the', 20 -> 'history', 21 -> 'books', 22 -> '.']\n"
     ]
    }
   ],
   "source": [
    "print(t.productions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToEdgeList(tree):\n",
    "    \"\"\"\n",
    "    input: NLTK Tree\n",
    "    output: list of tuples of edges of the form (source_node, destination_node)\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_list = []\n",
    "    for production in tree.productions():\n",
    "        for elem in production.rhs():\n",
    "            if type(elem) is not str and production.lhs().symbol() != \"\":\n",
    "                edge_list.append([int(str(production.lhs())), int(str(elem))])\n",
    "\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [0, 8],\n",
       " [0, 9],\n",
       " [0, 11],\n",
       " [0, 22],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [3, 4],\n",
       " [3, 6],\n",
       " [4, 5],\n",
       " [6, 7],\n",
       " [9, 10],\n",
       " [11, 12],\n",
       " [11, 13],\n",
       " [11, 16],\n",
       " [13, 14],\n",
       " [13, 15],\n",
       " [16, 17],\n",
       " [16, 18],\n",
       " [18, 19],\n",
       " [18, 20],\n",
       " [18, 21]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = convertToEdgeList(t)\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert node labels (i.e. Tags) to floats\n",
    "* First, open the file containing all possible tags\n",
    "* Create two dictionaries tags_to_ids and ids_to_tags\n",
    "* Convert the node labels to floats using the index of the tag in the tags_to_ids dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'ADJP': 0, '-ADV': 1, 'ADVP': 2, '-BNF': 3, 'CC': 4, 'CD': 5, '-CLF': 6, '-CLR': 7, 'CONJP': 8, '-DIR': 9, 'DT': 10, '-DTV': 11, 'EX': 12, '-EXT': 13, 'FRAG': 14, 'FW': 15, '-HLN': 16, 'IN': 17, 'INTJ': 18, 'JJ': 19, 'JJR': 20, 'JJS': 21, '-LGS': 22, '-LOC': 23, 'LS': 24, 'LST': 25, 'MD': 26, '-MNR': 27, 'NAC': 28, 'NN': 29, 'NNS': 30, 'NNP': 31, 'NNPS': 32, '-NOM': 33, 'NP': 34, 'NX': 35, 'PDT': 36, 'POS': 37, 'PP': 38, '-PRD': 39, 'PRN': 40, 'PRP': 41, '-PRP': 42, 'PRP$': 43, 'PRP-S': 44, 'PRT': 45, '-PUT': 46, 'QP': 47, 'RB': 48, 'RBR': 49, 'RBS': 50, 'RP': 51, 'RRC': 52, 'S': 53, 'SBAR': 54, 'SBARQ': 55, '-SBJ': 56, 'SINV': 57, 'SQ': 58, 'SYM': 59, '-TMP': 60, 'TO': 61, '-TPC': 62, '-TTL': 63, 'UCP': 64, 'UH': 65, 'VB': 66, 'VBD': 67, 'VBG': 68, 'VBN': 69, 'VBP': 70, 'VBZ': 71, '-VOC': 72, 'VP': 73, 'WDT': 74, 'WHADJP': 75, 'WHADVP': 76, 'WHNP': 77, 'WHPP': 78, 'WP': 79, 'WP$': 80, 'WP-S': 81, 'WRB': 82, ',': 83, '.': 84, 'X': 85})\n"
     ]
    }
   ],
   "source": [
    "# TODO: convert nodes to float - onehot, or embeddings\n",
    "# if onehot, get all possible POS tags to create table\n",
    "# http://surdeanu.cs.arizona.edu/mihai/teaching/ista555-fall13/readings/PennTreebankConstituents.html\n",
    "# https://www.cis.upenn.edu/~bies/manuals/root.pdf\n",
    "\n",
    "tags_to_ids = defaultdict(str)\n",
    "ids_to_tags = defaultdict(int)\n",
    "\n",
    "with open('pennTreeBankTags.txt','r') as _f:\n",
    "    lines = _f.readlines()\n",
    "    for idx,line in enumerate(lines):\n",
    "        ids_to_tags[idx]=line.strip()\n",
    "        tags_to_ids[line.strip()]=idx\n",
    "        \n",
    "print(tags_to_ids)\n",
    "# print(ids_to_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "Note that it is necessary that the elements in edge_index only hold indices in the range { 0, ..., num_nodes - 1}. This is needed as we want our final data representation to be as compact as possible, e.g., we want to index the source and destination node features of the first edge (0, 1) via x[0] and x[1], respectively. You can always check that your final Data objects fulfill these requirements by running validate():\n",
    "\n",
    "data.validate(raise_on_error=True)\n",
    "\n",
    "edges = \n",
    "```\n",
    "[[0, 1],\n",
    " [0, 8]\n",
    " ...\n",
    "]\n",
    "```\n",
    "nodes_dict = \n",
    "```\n",
    "{0: 'S',\n",
    " 1: 'SBAR',\n",
    " 2: 'IN',\n",
    " 3: 'S',\n",
    " ...\n",
    " 8: ',',\n",
    " 9: 'NP',\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "nodes_ids == x\n",
    "```\n",
    "x[0] -> 'S' -> embed('S') -> [...]\n",
    "x[1] -> 'SBAR'\n",
    "x[2] -> 'IN'\n",
    "x[3] -> 'S'\n",
    "...\n",
    "x[8] -> ','\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ids = [[tags_to_ids[v]/100] if v in tags_to_ids.keys() else [0.83] for k,v in nodes_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.53],\n",
       " [0.54],\n",
       " [0.17],\n",
       " [0.53],\n",
       " [0.34],\n",
       " [0.41],\n",
       " [0.73],\n",
       " [0.71],\n",
       " [0.83],\n",
       " [0.34],\n",
       " [0.41],\n",
       " [0.73],\n",
       " [0.71],\n",
       " [0.34],\n",
       " [0.31],\n",
       " [0.31],\n",
       " [0.38],\n",
       " [0.17],\n",
       " [0.34],\n",
       " [0.1],\n",
       " [0.29],\n",
       " [0.3],\n",
       " [0.84]]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"unknown_tags_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "``\n",
      "-RRB-\n",
      "HYPH\n",
      "''\n",
      "NFP\n",
      "-LRB-\n",
      "NML\n",
      ":\n",
      "$\n"
     ]
    }
   ],
   "source": [
    "for t in set(df['TAG']):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Use FastText to generate POS tag embeddings\n",
    "* Convert text to parse strings\n",
    "* Train FastText on parse strings to obtain embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_tags = []\n",
    "nodes_ids = []\n",
    "for n in nodes:\n",
    "    if n not in tags_to_ids.keys():\n",
    "        unknown_tags.append(n)\n",
    "        nodes_ids.append([83])\n",
    "    else:\n",
    "        nodes_ids.append([tags_to_ids[n]])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('unknown_tags_test.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['TAG']) #header\n",
    "    write.writerows(unknown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Appeal_to_Authority',\n",
    "     'Appeal_to_fear-prejudice',\n",
    "     'Bandwagon',\n",
    "     'Black-and-White_Fallacy',\n",
    "     'Causal_Oversimplification',\n",
    "     'Doubt',\n",
    "     'Exaggeration,Minimisation',\n",
    "     'Flag-Waving',\n",
    "     'Loaded_Language',\n",
    "     'Name_Calling,Labeling',\n",
    "     'Obfuscation,Intentional_Vagueness,Confusion',\n",
    "     'Red_Herring',\n",
    "     'Reductio_ad_hitlerum',\n",
    "     'Repetition',\n",
    "     'Slogans',\n",
    "     'Straw_Men',\n",
    "     'Thought-terminating_Cliches',\n",
    "     'Whataboutism',\n",
    "     'Not_Propaganda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a PYG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "x = torch.tensor(nodes_ids, dtype=torch.float)\n",
    "y = torch.tensor([names.index(\"Bandwagon\")], dtype=torch.long)\n",
    "\n",
    "\n",
    "datum = Data(x=x, y=y, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[23, 1], edge_index=[2, 22], y=[1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datum.is_directed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next section : make a list of all datapoints, and save it using DataLoader and Dataset\n",
    "* data_list = [datum1, datum2, ..., datumN]\n",
    "* loader = DataLoader(data_list, batch_size=32)\n",
    "* data, slices = Dataset.collate(data_list)\n",
    "* torch.save((data, slices), 'data/ptc_trees_sample.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do it for the whole dataset\n",
    "#### See the makePYGdata.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'makePYGdata' from '/Users/kylehamilton/MyDocuments/ML-Labs/propaganda-detection/GNN/makePYGdata.py'>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset, download_url\n",
    "import makePYGdata as mpd\n",
    "import importlib\n",
    "importlib.reload(mpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Found cached dataset parquet (/Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--PTC_Corpus-dc238a4991580b39/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c57ef6d8d4d475dbe9a9377c343ceb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--PTC_Corpus-dc238a4991580b39/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-aad3be4b871c993a_*_of_00004.arrow\n",
      "Loading cached processed dataset at /Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--PTC_Corpus-dc238a4991580b39/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-910b135e91c33b38_*_of_00004.arrow\n",
      "Loading cached processed dataset at /Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--PTC_Corpus-dc238a4991580b39/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-9d6dfebae211e075_*_of_00004.arrow\n",
      "processing sentence::   0%|                                                                                                                                | 0/14434 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "processing sentence:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14434/14434 [37:07<00:00,  6.48it/s]\n",
      "processing sentence:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2067/2067 [05:13<00:00,  6.60it/s]\n",
      "processing sentence:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4083/4083 [10:23<00:00,  6.55it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "some_data = mpd.PTC_Trees_Dataset(root='data_undirected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTC_Trees_Dataset(20584)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vars(some_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_data_list', '_download', '_indices', '_infer_num_classes', '_is_protocol', '_process', 'collate', 'copy', 'data', 'download', 'get', 'get_summary', 'index_select', 'indices', 'len', 'log', 'num_classes', 'num_edge_features', 'num_features', 'num_node_features', 'pre_filter', 'pre_transform', 'print_summary', 'process', 'processed_dir', 'processed_file_names', 'processed_paths', 'raw_dir', 'raw_file_names', 'raw_paths', 'root', 'shuffle', 'slices', 'transform']\n"
     ]
    }
   ],
   "source": [
    "print(dir(some_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20584\n"
     ]
    }
   ],
   "source": [
    "print(some_data.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(some_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_get_shared_seed', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'exclude_keys', 'follow_batch', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']\n"
     ]
    }
   ],
   "source": [
    "print(dir(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_data_list', '_download', '_indices', '_infer_num_classes', '_is_protocol', '_process', 'collate', 'copy', 'data', 'download', 'get', 'get_summary', 'index_select', 'indices', 'len', 'log', 'num_classes', 'num_edge_features', 'num_features', 'num_node_features', 'pre_filter', 'pre_transform', 'print_summary', 'process', 'processed_dir', 'processed_file_names', 'processed_paths', 'raw_dir', 'raw_file_names', 'raw_paths', 'root', 'shuffle', 'slices', 'transform']\n"
     ]
    }
   ],
   "source": [
    "print(dir(loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__cat_dim__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__inc__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_all_edges_to_layout', '_edge_attr_cls', '_edge_to_layout', '_get_edge_index', '_get_tensor', '_get_tensor_size', '_multi_get_tensor', '_put_edge_index', '_put_tensor', '_remove_tensor', '_store', '_tensor_attr_cls', '_to_type', 'apply', 'apply_', 'batch', 'clone', 'coalesce', 'contains_isolated_nodes', 'contains_self_loops', 'contiguous', 'coo', 'cpu', 'csc', 'csr', 'cuda', 'debug', 'detach', 'detach_', 'edge_attr', 'edge_index', 'edge_stores', 'edge_weight', 'from_dict', 'get_all_edge_attrs', 'get_all_tensor_attrs', 'get_edge_index', 'get_tensor', 'get_tensor_size', 'has_isolated_nodes', 'has_self_loops', 'is_coalesced', 'is_cuda', 'is_directed', 'is_edge_attr', 'is_node_attr', 'is_undirected', 'items', 'keys', 'multi_get_tensor', 'node_stores', 'num_edge_features', 'num_edges', 'num_faces', 'num_features', 'num_node_features', 'num_nodes', 'pin_memory', 'pos', 'put_edge_index', 'put_tensor', 'record_stream', 'remove_tensor', 'requires_grad_', 'share_memory_', 'size', 'stores', 'stores_as', 'subgraph', 'to', 'to_dict', 'to_heterogeneous', 'to_namedtuple', 'update_tensor', 'validate', 'view', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(dir(loader.dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18,  9,  8,  ...,  7, 18, 18])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3400],\n",
       "        [0.3400],\n",
       "        [0.8300],\n",
       "        [0.8300],\n",
       "        [0.3100]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data['x'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 2, 2, 2], dtype=torch.uint8)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'split', 'x', 'edge_index']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  0,  ...,  7,  6,  8],\n",
       "        [ 1,  0, 11,  ...,  6,  8,  6]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data['edge_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset.data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_dataset = loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[14, 1], edge_index=[2, 26], y=[1], split=[1])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
